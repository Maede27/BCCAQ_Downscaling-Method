# Compute-Canada-Graham-commands

Install PuTTY to connect to the Compute Canada (Graham Server)
Copy graham.computecanada.ca to Host Name or IP address in PuTTY, then select SSH and open 
After connecting to CC server, navigate to home/mehdisam
To install the R packages, you need to load "netcdf" module in addition to gcc and R:

module load gcc r netcdf udunits

Some R packages like "pbdNCDF4" are removed from the official mirrors and you need to download the sources files first:
wget https://cran.r-project.org/src/contrib/Archive/pbdNCDF4/pbdNCDF4_0.1-4.tar.gz

Now run R : 
R

In R environment:
> install.packages("ncdf4")
> #install.packages("/home/mehdisam/pbdNCDF4_0.1-4.tar.gz", repos = NULL, type="source") ## we don't need this package for downscaling
> library(ClimDown)
> library(ncdf4) 
#### read GCM file
> merge_new<-"pr_tasmax_tasmin.nc"
> mergedfile<-nc_open(merge_new)
#### read observation file
> fn_obs<-"/home/najafim/scratch/lake_winnipeg/Livneh_2015/livneh-red_assiniboine.nc"
> obs<-nc_open(fn_obs, write=TRUE)
#### rename variables in observation data via R as the variables have different names in observ and GCM files
> old_varname <-'Prec' #precipitation variable
> new_varname <-'pr'
> obs<- ncvar_rename(obs, old_varname, new_varname, verbose=FALSE)
#### or rename variables in observation data via cdo module in server (latter is better than former for renaming!)
####to load cdo module on Compute Canada:
module load intel/2018.3 openmpi/3.1.2 cdo/1.9.5 nco/4.6.6 
cdo chname,Prec,pr /home/najafim/scratch/lake_winnipeg/Livneh_2015/livneh-red_assiniboine.nc  livneh-red_assiniboine_1.nc
cdo chname,Tmax,tasmax /home/najafim/scratch/lake_winnipeg/Livneh_2015/livneh-red_assiniboine_1.nc  livneh-red_assiniboine_2.nc
cdo chname,Tmin,tasmin /home/najafim/scratch/lake_winnipeg/Livneh_2015/livneh-red_assiniboine_2.nc  livneh-red_assiniboine_renamed.nc

#### modify the variables' units in observation data (change C to celsius and mm to kg m-2 d-1)
cdo chunit,C,celsius livneh-red_assiniboine_renamed.nc  livneh-red_assiniboine_renamed_celsius.nc
cdo setattribute,pr@units="kg m-2 d-1" livneh-red_assiniboine_renamed_celsius.nc  livneh-red_assiniboine_renamed_modifiedUnits.nc

### BCCAQ in R 
> library(ncdf4)
> library(ClimDown)
> GCM<-"/home/najafim/scratch/lake_winnipeg/GCMs/CanESM5_raw_to_clip/step3-cdo_sellonlat-file/pr_tasmax_tasmin_Amon_CanESM5_h_ssp245_r1i1p1f1_1850-2100_clipped.nc"
> Obs<-"/home/najafim/scratch/lake_winnipeg/GCMs/Test_Obs_GCM/Test_Obs_newLon_sameVar_sameUnit.nc"
>#### repeat for each variable:
> bccaq.netcdf.wrapper(GCM, Obs, "nc_out_tasmax.nc", varname = "tasmax") #creates the file nc_out_tasmax.nc where the downscaled data will be stored on the server


### Useful links:
https://code.mpimet.mpg.de/projects/cdo/wiki/Tutorial
https://www.unidata.ucar.edu/software/netcdf/workshops/2011/utilities/NcdumpExamples.html


### useful link to rotate lon from -180 to 180 to 0 to 360
https://sourceforge.net/p/nco/discussion/9830/thread/c527a930/?limit=25

#### nco command to rotate longitude in observation data from -180~180 to 0~360
#### first load the module nco:
module load intel/2018.3 openmpi/3.1.2 cdo/1.9.5 nco/4.6.6

ncap2 -O -s 'where(lon<0) lon=lon+360; where(lon<0) lon=lon+360' livneh-red_assiniboine_renamed_modifiedUnits_lon.nc obs_lon_nco.nc

#### to make the file readable, writable and executable in the server for everyone 
chmod 777 filename

####to be able to load both r and cdo modules at the same time on the server:
module load cdo/1.7.2  r/3.5.0


#### To submit a job on Graham
#check the version of modules on the directory by :
[name@server ~]$ module list
#Load the modules R, gcc and netcdf with the required version:
[name@server ~]$ module load gcc/5.4.0  r/3.5.2  netcdf/4.4.1.1
#install R packages with these commands: 
[name@server ~]$ mkdir -p $HOME/R_libs
[name@server ~]$ export R_LIBS=$HOME/R_libs
[name@server ~]$ R -e 'install.packages("ncdf4", repos="https://cloud.r-project.org/")'
[name@server ~]$ R -e 'install.packages("ClimDown", repos="https://cloud.r-project.org/")'
#create Rscript and bash script for job submission:
[name@server ~]$ nano run-CanESM5_job.sh
[name@server ~]$ nano R_climdown_CanESM5.R
#place your code in these two files. (the job and R scripts are available on this GitHub page)

#Then, install ClimDown and ncdf4 packages on R in the directory to make sure they are installed!
# And finally, submit the job:
[name@server ~]$ sbatch run-CanESM5_job.sh  


#### To edit Rprofile in R:
#Changed the calibration.start and calibration.end . Copied the content of the config file in Rprofile in R environment on Graham using the following command:
file.edit(".Rprofile")         # edit project specific .Rprofile

#To edit R profile in Home:
file.edit(file.path("~", ".Rprofile")) # edit .Rprofile in HOME

#### congig.R:
.onLoad <- function(libname, pkgname) {
    op <- options()
    cd.options <- list(
        # Computation options
        max.GB=1,
        # CA options
        trimmed.mean=0,
        delta.days=45,
        n.analogues=30,
        calibration.start=as.POSIXct('1971-01-01', tz='GMT'),
        calibration.end=as.POSIXct('2005-12-31', tz='GMT'),
        tol=0.1,
        expon=0.5,
        # QDM options
        multiyear=TRUE,
        expand.multiyear=TRUE,
        multiyear.window.length=30,
        trace=0.005,
        jitter.factor=0.01,
        tau=list(pr=1001, tasmax=101, tasmin=101),
        seasonal=list(pr=TRUE, tasmax=FALSE, tasmin=FALSE),
        ratio=list(pr=TRUE, tasmax=FALSE, tasmin=FALSE),
        # Data processing options
        check.units=TRUE,
        check.neg.precip=TRUE,
        target.units=c(tasmax='celsius', tasmin='celsius', pr='kg m-2 d-1') ##pr='mm day-1')
    )

    toset <- !(names(cd.options) %in% names(op))

    if(any(toset)) options(cd.options[toset])
}


#Takes a vector length and chunk size
#returns a list of (start, stop, length)
chunk.indices <- function(total.size, chunk.size) {
  lapply(
    split(1:total.size, ceiling(1:total.size / chunk.size)),
    function(x) {c('start'=min(x), 'stop'=max(x), 'length'=length(x))}
    )
}

optimal.chunk.size <- function(n.elements, max.GB=getOption('max.GB')) {
  #8 byte numerics
  floor(max.GB * 2 ** 30 / 8 / n.elements)
}

#Takes a vector of PCICt dates and chunk.size and splits the vector into chunks
#that are *approximately* of that size, but only break on the boundaries
#between months
chunk.month.factor <- function(t, chunk.size) {
    time.factor <- factor(format(t, '%Y-%m'))
    chunk.factor <- factor(ceiling(1:length(t) / chunk.size))
    f <- interaction(time.factor, chunk.factor, drop=T)

    # Do two passes across the levels of the factor:
    # The first pass merges a month across chunk boundaries
    nl <- nlevels(f)
    new.levels <- mapply(
        function(prev, this) {
            prev.month <- strsplit(prev, '.', fixed=T)[[1]][1]
            this.month <- strsplit(this, '.', fixed=T)[[1]][1]
            if (prev.month == this.month) {
                prev
            }
            else {
                this
            }
        },
        levels(f)[1:nl-1], levels(f)[2:nl]
        )
    # The second pass eliminates the months from the factor
    levels(f) <- gsub('.*\\.(.*)', '\\1', c(levels(f)[1], new.levels))
    f
}


#### to give access to a folder:
[name@server ~]$ chmod -R 777 .  (with '.' at the end)
